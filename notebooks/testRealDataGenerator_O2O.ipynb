{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b40753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaleCmToPx 0.09598826886969584\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy.linalg import inv\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from DON_Picking.Configuration import config,SINGLE_OBJECT_WITHIN_SCENE\n",
    "\n",
    "from DON_Training.DataGenerator_O2O import DataGenerator,loadAllModels,convertToHeatmap\n",
    "from ITRIP.objects_new import graspnet_train\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fd1c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n",
      "[14 17 18  7 21 27 66 63 60]\n",
      "Loaded 87 models in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "path = \"../../dataDON/test_seen/scene_0105\"\n",
    "listObj = np.loadtxt(path+\"/object_id_list.txt\").astype(np.uint8)\n",
    "print (listObj.shape)\n",
    "print (listObj)\n",
    "\n",
    "dataGenerator = DataGenerator()\n",
    "models, colors = loadAllModels(path=\"../../dataDON/\",loadFile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80d460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87 models in  2.8371810913085938e-05  seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "end_time = time.time()\n",
    "print (\"Loaded 87 models in \",end_time-start_time,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b393fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator.setOriginalModelObjects(models, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff916363",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../dataDON/test_seen/scene_0105/realsense/000005_rgb.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1424815bf2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mposeCamera\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageColor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmentMap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muvSegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrObjectPose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataGenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImageData_Real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/realsense\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ITRIGrasp/DON_Training/DataGenerator_O2O.py\u001b[0m in \u001b[0;36mgetImageData_Real\u001b[0;34m(self, pathScene, idx)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetImageData_Real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpathScene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mposeCamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mimageColor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathScene\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/%06d_rgb.jpg\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0mimageColor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageColor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# mask = np.array(Image.open(pathScene + \"/%06d_mask.png\" % (idx)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ITRI_Project/venv/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../dataDON/test_seen/scene_0105/realsense/000005_rgb.jpg'"
     ]
    }
   ],
   "source": [
    "poseCamera, imageColor, depth, mask, indexMap, segmentMap,uvSegment, arrObjectPose = dataGenerator.getImageData_Real(path+\"/realsense\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6594399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (imageColor.shape)\n",
    "\n",
    "imageColor = imageColor[:,380:1100,:]\n",
    "\n",
    "imageColor = cv2.cvtColor(imageColor, cv2.COLOR_BGR2RGB)\n",
    "newsize = (256,256)\n",
    "imageColorX = Image.fromarray(imageColor)\n",
    "imageColorX = imageColorX.resize(newsize)\n",
    "\n",
    "imageColor = np.array(imageColorX)\n",
    "print (imageColor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d08ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from transforms3d.quaternions import quat2mat\n",
    "xmldoc = minidom.parse(path+\"/realsense/annotations/0005.xml\")\n",
    "itemlist = xmldoc.getElementsByTagName('obj')\n",
    "print(len(itemlist))\n",
    "\n",
    "arrObjectPose = np.zeros(((len(itemlist)+1)*4,4))\n",
    "i = 1\n",
    "for item in itemlist:\n",
    "    #print (item.getElementsByTagName(\"obj_id\").item(0).firstChild.nodeValue)\n",
    "    #print (item.getElementsByTagName(\"pos_in_world\").item(0).firstChild.nodeValue)\n",
    "    strQuat =  item.getElementsByTagName(\"ori_in_world\").item(0).firstChild.nodeValue\n",
    "    strPos = item.getElementsByTagName(\"pos_in_world\").item(0).firstChild.nodeValue\n",
    "    #print (strQuat)\n",
    "    quat = np.fromstring(strQuat,sep=' ')\n",
    "    T =   np.fromstring(strPos,sep=' ')\n",
    "    \n",
    "    R =  quat2mat(tuple(quat))\n",
    "    \n",
    "    objectPose = np.zeros((4,4))\n",
    "    objectPose[:3,:3] = R\n",
    "    objectPose[3,3] = 1\n",
    "    objectPose[:3,-1] = T\n",
    "    #print (objectPose)\n",
    "    arrObjectPose[i*4:(i+1)*4] = objectPose\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "def adjust_color_lightness(r, g, b, factor):\n",
    "    h, l, s = rgb_to_hls(r / 255.0, g / 255.0, b / 255.0)\n",
    "    l = max(min(l * factor, 1.0), 0.0)\n",
    "    r, g, b = hls_to_rgb(h, l, s)\n",
    "    return int(r * 255), int(g * 255), int(b * 255)\n",
    "\n",
    "\n",
    "def lighten_color(r, g, b, factor=0.1):\n",
    "    return adjust_color_lightness(r, g, b, 1 + factor)\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from colorsys import rgb_to_hls, hls_to_rgb\n",
    "img = np.zeros((imageColor.shape))\n",
    "img = Image.fromarray(np.uint8(img))\n",
    "renderMap = np.zeros((imageColor.shape[0], imageColor.shape[1]))-10\n",
    "\n",
    "draw = ImageDraw.Draw(imageColorX)\n",
    "\n",
    "print (renderMap[50,50])\n",
    "for obj_th in range (5):\n",
    "    print (obj_th)\n",
    "    vertex = models[listObj[obj_th]]\n",
    "    colorCoord = colors[listObj[obj_th]]\n",
    "    objPose = arrObjectPose[(obj_th + 1) * 4:(obj_th + 2) * 4]\n",
    "    #print(objPose)\n",
    "\n",
    "    intrinsicCamera = np.load(path+\"/realsense/camK.npy\")\n",
    "\n",
    "    projectedImage = np.matmul((intrinsicCamera), np.matmul((objPose[:3]), (vertex.T)))\n",
    "    scale = 1 / projectedImage[2, :]\n",
    "    projectedImage *= scale\n",
    "\n",
    "    projectedImage[2, :] = scale\n",
    "    projectedImage[0, :] -= 380\n",
    "    \n",
    "    #projectedImage[:2, :] += 1280//2\n",
    "\n",
    "    uvCoord = projectedImage.T  / 2.8125\n",
    "    \n",
    "    nVertext = uvCoord.shape[0]\n",
    "    \n",
    "    step = 3\n",
    "    \n",
    "    #print (np.min(vertex[:,2]))\n",
    "\n",
    "    for i in range(nVertext):\n",
    "        u = (int)(uvCoord[i, 0])\n",
    "        v = (int)(uvCoord[i, 1])\n",
    "        #print (u,v)\n",
    "        #print (vertex[i,2])  \n",
    "        if ( 0< u < config[\"W\"] and  0 <  v < config[\"W\"] ):\n",
    "            if (vertex[i,2] > renderMap[v, u]):\n",
    "                renderMap[v:v + step, u:u + step] = uvCoord[i, 2]\n",
    "                r, g, b = (tuple(colorCoord[i]))\n",
    "                r,g,b = lighten_color(r, g, b, 0.1)\n",
    "\n",
    "                draw.rectangle((u, v, u + step, v + step), fill=(r,g,b))\n",
    "#print (uvCoord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)\n",
    "display(imageColorX)\n",
    "print (segmentMap.shape)\n",
    "segmentMap = segmentMap[:,380:1100]\n",
    "print (segmentMap.shape)\n",
    "segmentMapX = convertToHeatmap(segmentMap)\n",
    "segmentMapX = segmentMapX.resize((256,256))\n",
    "mask = np.clip(segmentMap,0,1)\n",
    "print (depth.shape)\n",
    "maskX = convertToHeatmap(mask)\n",
    "display(segmentMapX)\n",
    "display(maskX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c2ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7af6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
